Instructions for "On demand date on AWS"

On demand date on AWS EC2 and S3
	get_service_date = 'on_demand'
	python_processing = 'aws_ec2'
	ttm_graph_processing = 'aws_ec2'
	web_client_hosted_on = 'aws_s3'
	ttm_server_on = 'aws_ec2'

=============================================================================================

0. Using Putty (see setup instructions for putty setup in "AWS version setup.txt"), connect to the EC2.
	Change directory to Trasnit Analyst Israel project:
$ cd TransitAnalystIsrael
	Make sure that the Project dir structure is as below, and create missing folders if needed using mkdir:   
	a. The starting dir structure under TransitAnalystIsrael (name is given by git project, don't change it) is explained below:
		gtfs 					- GTFS unzipped dir is placed in this dir
		osm 					- Open Street Map file for Israel is downloaded to this dir for the TTM tool
		processed 				- this dir can start out empty, it will hold all the processed data files produced by the python scripts
		root					- this dir holds the python scripts that process the GTFS files about 50 files. 
									See the flows presentation to see how they are used.
		static_data				- this dir holds the 8 or so data files that do not change every month. They are copied into the processed dir before processing starts.
		website_no_data			- this dir holds the client side html and js code for the tools, without the processed data. 
									the files in this dir are copied into the dir website_current together with the processed data to create the tools

		website_current			- used only in Monthly auto update on AWS, this output dir will hold the tools and processed data to display for the current month
		website_past			- used only in Monthly auto update on AWS, this output dir will hold the tools and processed data to display for the past month
		AWS Lambda function 	- used only in Monthly auto update on AWS 
		
	b. note that the on-demand date output dir for the tools - website_yyyymmdd - does not exist prior to processing. It will be created by the scripts in the same parent dir.

1. Update the config file - ~/TransitAnalystIsrael/root/transitanalystisrael_config.py 
	a. remove "#" from the "On demand date on AWS EC2 and S3" to un-comment parameters to look as below:

#On demand date on AWS EC2 and S3
get_service_date = 'on_demand'
python_processing = 'aws_ec2'
ttm_graph_processing = 'aws_ec2'
web_client_hosted_on = 'aws_s3'
ttm_server_on = 'aws_ec2'

	b. make sure all the rest of the 6 product processing configurations are commented out - have "#"in the first char of the line.

	c. change "gtfsdate" and "serviceweekstartdate" to the requested on-demand date e.g. for 20190302 (YYYYMMDD)

gtfsdate = '20190302'
serviceweekstartdate = '20190302'

	d. save the config file

2. Downloading or copying the GTFS zip file to the AWS (two options 2.1 and 2.2): 
2.1 Downloading from  HTTP/FTP website: 
	a. Locate GTFS files that corespond to a service start date that is equal to the on-demand date. Remeber that GTFS is uploaded to MOT servers (ftp://gtfs.mot.gov.il) at 10pm each day with a service start date of that same day. Alternitivly, for GTFS files from past dates download from the  transitfeeds website (now part of OpenMobilityData) - https://transitfeeds.com/p/ministry-of-transport-and-road-safety/820 - download URL for example for 06 March 2019: https://transitfeeds.com/p/ministry-of-transport-and-road-safety/820/20190306
    b. Connect to the EC2 using putty
	c. Change directory to the GTFS folder:
$ cd TransitAnalystIsrael/gtfs/
	d. Download the file - url is provided as example:
$ wget https://transitfeeds.com/p/ministry-of-transport-and-road-safety/820/20190306
	e. Rename the downlaoded file named "download" to be gtfsdirbase+gtfsdate+'.zip' (as in the config file) e.g. 'israel20190306.zip':
$ mv download israel20190306.zip
	
2.2 Copying from a gtfs file from your local host. File name for example gtfs.zip:
	In order to copy the file from your machine to the EC2, you need the .pem key that allows you to access the EC2 (you got the .pem key when you created the EC2 instance - probably in the s3 key bucket). 
	a. Place both the gtfs file and the key in the same folder.
	b. Right-click in the widnows explorer -> Open "Git Bash" here
	c. The copy command requries the following infromation:
	   i. the name of the .pem file <pem-file>.pem, e.g. key.pem
	   ii. name of the gtfs file <gtfs-file>.zip, e.g. gtfs.zip
	   iii. user name that you use to connect to the EC2 with putty <user-name>, e.g. ubuntu
	   iv. public DNS of the EC2 instace that can be found at the AWS EC2 console (http://console.aws.amazon.com/ec2) -> in the EC2 instances list -> column "Public DNS (IPv4)"), <public-dns>, e.g. ec2-3-122-15-201.eu-central-1.compute.amazonaws.com
	d. Type the command: "scp -i <pem-file>.pem <gtfs-file>.zip <user-name>@<public-dns>:/home/ubuntu/TransitAnalystIsrael/gtfs/" e.g.
$ scp -i key.pem israel20190303.zip ubuntu@ec2-3-122-15-201.eu-central-1.compute.amazonaws.com:/home/ubuntu/TransitAnalystIsrael/gtfs/
	e. Rename the copied file e.g. "gtfs.zip" be gtfsdirbase+gtfsdate+'.zip' (as in the config file) e.g. 'israel20190306.zip':
$ mv gtfs.zip israel20190306.zip

3. Download the Open Street Map - OSM file:
	a. Locate the current or recent Israel OSM file or one that coresponds to the on-demand date. The latest can be downloaded from  http://download.geofabrik.de/asia/israel-and-palestine.html
    b. Connect to the EC2 using putty
	c. Change directory to the osm folder:
$ cd TransitAnalystIsrael/osm/
	d. Download the file - url is provided as example:
$ wget https://download.geofabrik.de/asia/israel-and-palestine-latest.osm.pbf
	e. Rename the downlaoded file named "download" to be 'israel-and-palestine-latest.osm.pbf'
$ mv download israel-and-palestine-latest.osm.pbf


4. Run the Navitia docker environment
	a. Go to the folder where you cloned the Navitia-docker-compose repo e.g.:
$ cd ~/navitia-docker-compose	
	b. type at the terminal:
$ sudo docker-compose -f compose_files/docker-compose.yml -p navitia-docker-compose up --remove-orphans

a. Open a new Putty session (don't touch the existing one - you can close the window - the docker will continue running)
	b. Change directory to Transit Analyst Israel project root folder:
$ cd TransitAnalystIsrael/root	
	The following command will trigger the update process. 
	Using 'nohup'  means that the program is running and you can safely close the Putty window without stopping the execution.
	Right away the following line appears: "nohup: ignoring input and appending output to 'nohup.out'" - this is a good sign and nothing else should appear after.	
	If you want to see the output on screen remove "nohup" from the command - but then closing the putty windows will STOP THE EXECUTION. so you have to make sure your local(!) machine
	is up and running for the next 4-5 hours.

	c. Type 'nohup python3 transitanalystisrael_v1.py'
$ nohup python3 transitanalystisrael_v1.py
	
	d. To view the status, open a new Putty session
		Navitigate to the logs directory:
$ cd TransitAnalystIsrael/root/logs/
		Display the possible logs files:
$ ls
		View the current log file:
		$ vim <log file name> (e.g. Transit Analyst27032019_1318.txt)
$ vim Transit Analyst27032019_1318.txt
		Quit by Pressing Ecs -> typing q!
$ q!
	   
		You can recheck this log from time to time. If an error occurs you will see it in the log.
		Additional, when finishing succesfuly or unsucessfuly, the log will be sent to transitanalystisrael@gmail.com

6. Wait about 4.5 hours for the scripts to run to completion

9. To run the TransitAnalystIsrael web client, go to the URL generated for the S3 that stores it, such as: https://s3.eu-central-1.amazonaws.com/ondemand-YYYYMMDD/indexh.html where YYYYMMDD is the on demand date you set in the gtfsdate (you can also access from the S3 console)

===================================================================================================================================

10. When done, stop and quit
	a. Using putty connect to the EC2
	b. stop the navitia docker containers by typing at the terminal:
$ docker stop $(docker ps -a -q)
	c. Connect to the AWS console (http://console.aws.amazon.com/ec2), right-click on the running instance -> Instance State -> Stop
	d. close the browser window where transitanalistisrael is running (they are still accessible on the S3 at any time)

====================================================================================================================================

11. To restart TransitAnalystIsrael for an existing auto date	
	a.Connect to the AWS console (http://console.aws.amazon.com/ec2), right-click on the stopped instance -> Instance State -> Start. 
	   docker and docker-compose dameons are brought up automatically.
	b. Using putty connect to the EC2	
	c. Go to the folder where you cloned the Navitia-docker-compose repo e.g.:
$ cd ~/navitia-docker-compose	
	d. type at the terminal:
$ sudo docker-compose -f compose_files/docker-compose-ondemand-YYYYMMDD.yml -p navitia-docker-compose up --remove-orphans (where YYYYMMDD is the date you put for the gtfsdate)
	e. See step 9 to access the web files (you can also access from the S3 console)	
	






